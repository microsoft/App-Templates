## AI Apps Template
The table below provides a list of GitHub repositories containing intelligent apps using Azure Open AI service with detailed information on deployment, use cases, technologies utilized, deployment steps, and more.
These repositories serve as a source of inspiration for creating and deploying a functional Proof of Concept (PoC) or MVP ( Minimal Valueable Product) and they are not intended for production use.

We collect more metadata about ai apps samples listed below. You can consult them in this [spreadsheet](openai-apps-catalogue.xlsx)

<table width: 100% >
    <tr class="first-row">
        <th>Repo & Description</th>
        <th>AI Patterns & LLM Capabilities</th>
        <th>Frameworks and Azure Services</th>
    </tr>
      <tr>
        <td>[AI Multi-Agent Architecture 3 or 5 days POC](https://github.com/MSUSAzureAccelerators/Azure-Cognitive-Search-Azure-OpenAI-Accelerator).
        Your organization requires a Multi-Channel Smart Chatbot and a search engine capable of comprehending diverse types of data scattered across various locations</td>
        <td>chat with company documents, chat with  business data, chat with API, RAG, conversational chat, vector search </td>
        <td>Python, Langchain, AppService, AzureSql, CosmosDB, Azure AI Search, Document Intelligence</td>
    </tr>
        <tr>
        <td>https://github.com/Azure-Samples/chat-with-your-data-solution-accelerator.
        The Chat with your data Solution accelerator is a powerful tool that combines the capabilities of Azure AI Search and Large Language Models (LLMs) to create a conversational search experience. This solution accelerator uses an Azure OpenAI GPT model and an Azure AI Search index generated from your data, which is integrated into a web application to provide a natural language interface, including speech-to-text functionality, for search queries. Users can drag and drop files, point to storage, and take care of technical setup to transform documents. </td>
        <td>chat with company documents, RAG, conversational chat, vector search</td>
        <td>Python, Langchain, AppService, Functions, Azure AI Search, Azure AI Speech, Document Intelligence</td>
    </tr>
        <tr>
        <td>https://github.com/microsoft/chat-copilot. This sample allows you to build your own integrated large language model (LLM) chat copilot. The sample is built on Microsoft Semantic Kernel and has three components:
        A frontend application React web app
        A backend REST API .NET web API service deployed on App Service
        A .NET worker service for processing semantic memory using <a href="https://github.com/microsoft/kernel-memory">Kernel Memory</a>.
        <td>chat with company documents, RAG, statefull chat, vector search, document processing pipeline</td>
        <td>C#, Semantic Kernel, Kernel Memory, AppService, CosmosDB, Azure AI Search,Document Intelligence, Speech Service</td>
    </tr>    
    <tr>
        <td>https://github.com/AzureCosmosDB/cosmosdb-nosql-copilot.
        This sample application combines Azure Cosmos DB with Azure OpenAI to build a simple AI-enabled Chat Application. The application is written in C# on .NET 6 with a Blazor Server front-end and is hosted on Azure Web Apps. Conversational chats are staefull as the status is saved on cosmosdb</td>
        <td>virtual agent/assistant, chat with  business data, conversational chat, statefull chat</td>
        <td>C#, Semantic Kernel, AppService, CosmosDB</td>
    </tr>
    <tr>
        <td>https://github.com/Azure/Vector-Search-AI-Assistant/tree/cognitive-search-vector.
        The scenario for this sample centers around a consumer retail &quot;Intelligent Agent&quot; that allows users to ask questions on vectorized product, customer and sales order data stored in the database. The solution also includes key concepts such as managing conversational context and history, managing tokens consumed by Azure OpenAI Service. APIs and web application are hosted on AKS pods. Azure Cognitive Search is used as vector database.</td>
        <td>virtual agent/assistant, chat with  business data, RAG, conversational chat, statefull chat, vector search</td>
        <td>C#,Semantic Kernel, AKS, ACA, CosmosDB, Azure AI Search</td>
    </tr>
    <tr>
        <td>https://github.com/AzureCosmosDB/cosmosdb-mongo-copilot. The scenario for this sample centers around a consumer retail &quot;Intelligent Agent&quot; that allows users to ask questions on vectorized product, customer and sales order data stored in the database. The solution also includes key concepts such as managing conversational context and history, managing tokens consumed by Azure OpenAI Service. Backend is implemented using Azure Function web application is hosted on app services. MongoDB using CosmosDB-Mongovcore is used as vector database.</td>
        <td>virtual agent/assistant, chat with business data, RAG,conversational chat, statefull chat, vector search</td>
        <td>C#, Semantic Kernel, AppService, CosmosDB-MongoVCore</td>
    </tr>
    <tr>
        <td>https://github.com/microsoft/azurechatgpt. Azure Chat Solution Accelerator powered by Azure Open AI Service is a solution accelerator that allows organisations to deploy a private chat tenant in their Azure Subscription, with a familiar user experience and the added capabilities of chatting over your data and files. Web application is developed using typescript/next.js for backend and radixui for web themeing and components. The web apps is hosted on App Service</td>
        <td>chat with company documents, chat with API, RAG, statefull chat, vector search</td>
        <td>Nodejs, Typescript, Langchain,AppService, CosmosDB, Azure AI Search, Document Intelligence</td>   
    </tr>
    <tr>
        <td>https://github.com/Azure/gpt-rag. The RAG pattern enables businesses to use the reasoning capabilities of LLMs, using their existing models to process and generate responses based on new data. RAG facilitates periodic data updates without the need for fine-tuning, thereby streamlining the integration of LLMs into businesses.
The Enterprise RAG Solution Accelerator (GPT-RAG) offers a robust architecture tailored for enterprise-grade deployment of the RAG pattern. It ensures grounded responses and is built on Zero-trust security and Responsible AI, ensuring availability, scalability, and auditability. Ideal for organizations transitioning from exploration and PoC stages to full-scale production and MVPs. </td>
        <td>chat with company documents, RAG, personalized content generation, conversational chat, vector search, agents</td>
        <td>Python, nodejs, Semantic Kernel, Autogen, App Service, CosmosDB, Azure AI Search, FrontDoor</td>
    </tr>
    <tr>
        <td>https://github.com/MSUSAzureAccelerators/Knowledge-Mining-with-OpenAI. The purpose of this repo is to accelerate the deployment of a Python-based Knowledge Mining solution with OpenAI that will ingest a Knowledge Base, generate embeddings using the contents extracted, store them in a vector search engine (Cognitive Search), and use that engine to answer queries / questions specific to that Knowledge Base.
        The Cognitive Search component serves to make it easier to ingest a Knowledge Base with a variety of document formats. The Cognitive Services component connected to the Search makes it possible to have an enrichment pipeline. This pipeline can generate information based on images for example, which can be included at the time of generating embeddings.
        This repo also includes a guide to build a Power Virtual Agent bot that could be used and adapted to connect to this solution, to create an end-to-end Knowledge Base Chatbot. /</td>
        <td>chat with company documents, RAG, personalized content generation, conversational chat, vector search</td>
        <td>Python, Langchain, AppService, CosmosDB, Azure Redis Cache, Azure AI Search, Document Intelligence, ServiceBus, EventGrid
    </tr>
    <tr>
        <td>https://github.com/Azure-Samples/agent-openai-java-banking-assistant. This project is designed as a Proof of Concept (PoC) to explore the innovative realm of generative AI within the context of multi-agent architectures. By leveraging Java and Microsoft Semantic Kernel AI orchestration framework, our aim is to build a chat web app to demonstrate the feasibility and reliability of using generative AI agents to transform user experience from web clicks to natural language conversations while maximizing reuse of the existing workload data and APIs. /</td>
        <td>virtual assistant, conversational chat, tools calling, agents</td>
        <td>Java, Semantic Kernel, ACA, Document Intelligence</td>
    </tr>

</table>
